{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - File 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, voting_classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, ZeroPadding2D\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import / cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>hair_color</th>\n",
       "      <th>eyeglasses</th>\n",
       "      <th>smiling</th>\n",
       "      <th>young</th>\n",
       "      <th>human</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_name  hair_color  eyeglasses  smiling  young  human\n",
       "0          1           1           0        1      1      0\n",
       "1          2           4           0        1      1      1\n",
       "2          3           5           0        1      0      0\n",
       "6          7           2           0        1      1      0\n",
       "7          8           3           0        1      1      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data\n",
    "df = pd.read_csv('attribute_list.csv', skiprows=1)\n",
    "\n",
    "# reading pictures. Returning as np.array. Color level: RGB\n",
    "def read_pic(name, as_black_white=False):   \n",
    "    string = 'dataset/' + str(name) + '.png'\n",
    "    if as_black_white == True:\n",
    "        return(np.array(Image.open(string).convert(mode='L')))\n",
    "    else:\n",
    "        return(np.array(Image.open(string)))\n",
    "\n",
    "# Cleaning data\n",
    "def clean_data():\n",
    "    tmp = df[['hair_color', 'eyeglasses', 'smiling', 'young', 'human']]\n",
    "    tmp['sum'] = tmp.sum(axis=1)\n",
    "    t = tmp[tmp['sum'] == -5]\n",
    "    return(t.index + 1)\n",
    "df.drop(labels=clean_data()-1, inplace=True)\n",
    "\n",
    "# Converting (-1,1) to (0, 1)\n",
    "df['eyeglasses'] = (df['eyeglasses'] + 1) / 2\n",
    "df['smiling'] = (df['smiling'] + 1) / 2\n",
    "df['young'] = (df['young'] + 1) / 2\n",
    "df['human'] = (df['human'] + 1) / 2\n",
    "\n",
    "df['eyeglasses'] = df['eyeglasses'].apply(lambda x: int(x))\n",
    "df['smiling'] = df['smiling'].apply(lambda x: int(x))\n",
    "df['young'] = df['young'].apply(lambda x: int(x))\n",
    "df['human'] = df['human'].apply(lambda x: int(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4565, 256, 256, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Pictures\n",
    "def import_pictures(data, _as_black_white=False):\n",
    "    res = []\n",
    "    file_names = np.array(data['file_name'])\n",
    "    for k in file_names:\n",
    "        res.append(read_pic(k, as_black_white=_as_black_white)) # Data are alredy cleaned\n",
    "    return(np.array(res))\n",
    "\n",
    "pics_color = import_pictures(df)\n",
    "pics_color.shape # acces to an image: pics[name_of_img][x_pixel][y_pixel][RGB_color]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First try: black and white"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pictures in __black and white__ and __scaling__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4565, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "pics_b_w = import_pictures(df, _as_black_white=True)\n",
    "print(pics_b_w.shape)\n",
    "imgs = np.array([preprocessing.scale(pics_b_w[k]) for k in range(len(pics_b_w))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying __PCA__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, ravel\n",
    "def to_vector(data=pics_b_w):\n",
    "    res = []\n",
    "    for k in range(len(data)):\n",
    "        res.append(data[k].ravel())\n",
    "    return(np.array(res))\n",
    "\n",
    "pics_lin = to_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute pca.fit: 2.23 min\n",
      "Explained Variance: [4.80372054e-01 6.67785790e-02 4.88748002e-02 ... 2.79181849e-07\n",
      " 2.60685152e-07 9.47366833e-32]\n",
      "X99.shape (4565, 1746)\n",
      "Time to compute the two pca.fit_transform (95%, 99%): 2.11 min\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA\n",
    "s = time.time()\n",
    "pca = PCA()\n",
    "pca.fit(pics_lin)\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "print('Time to compute pca.fit: ' + str(int(100*(t - s)/60)/100) + ' min')\n",
    "\n",
    "print('Explained Variance:', pca.explained_variance_ratio_)\n",
    "# searching for number of component to keep\n",
    "v_exp = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "def extract_var(tbl, x=.95):\n",
    "    k = 0\n",
    "    while tbl[k] < x:\n",
    "        k = k + 1\n",
    "    return(k)\n",
    "\n",
    "k95 = extract_var(v_exp)\n",
    "k99 = extract_var(v_exp, x=.99)\n",
    "\n",
    "# X = pca.fit_transform(pics_lin)\n",
    "'''pca95 = PCA(n_components=k95)\n",
    "X95 = pca95.fit_transform(pics_lin)\n",
    "print('X95.shape', X95.shape)'''\n",
    "\n",
    "pca99 = PCA(n_components=k99)\n",
    "X99 = pca99.fit_transform(pics_lin)\n",
    "print('X99.shape', X99.shape)\n",
    "print('Time to compute the two pca.fit_transform (95%, 99%): ' + str(int(100*(time.time() - t)/60)/100) + ' min')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning - Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score: 98.57611571247072%\n",
      "0.9857612267250822\n"
     ]
    }
   ],
   "source": [
    "Y_human = np.array(df['human'])\n",
    "X_train_h, X_test_h, Y_train_h, Y_test_h = train_test_split(X99, Y_human, test_size=0.2)\n",
    "\n",
    "# Cross validation score\n",
    "c1 = np.mean(cross_val_score(MLPClassifier(), X99, Y_human, cv=6))\n",
    "print('Cross Validation score: ' + str(100*c1) + '%')\n",
    "\n",
    "# 'By hand'\n",
    "clf_neuralNetwork_human = MLPClassifier()\n",
    "clf_neuralNetwork_human.fit(X_train_h, Y_train_h)\n",
    "print(clf_neuralNetwork_human.score(X_test_h, Y_test_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 0 0 1 0 0 1 0 1]\n",
      "[4020 4021 4022 4023 4024 4025 4026 4027 4028 4029 4030 4031]\n"
     ]
    }
   ],
   "source": [
    "# Manual testing (possible because dataset already shuffled)\n",
    "ratio_train = 0.8\n",
    "Y = np.array(df['human'])\n",
    "names = np.array(df['file_name'])\n",
    "X_train, X_test = X99[:int(ratio_train*len(X99))], X99[int(ratio_train*len(X99)):] \n",
    "Y_train, Y_test = Y[:int(ratio_train*len(Y))], Y[int(ratio_train*len(Y)):]\n",
    "clf_neuralNetwork_mt = MLPClassifier()\n",
    "clf_neuralNetwork_mt.fit(X_train, Y_train)\n",
    "names_train, names_test = names[:int(ratio_train*len(X99))], names[int(ratio_train*len(X99)):]\n",
    "print(clf_neuralNetwork_mt.predict([X_test[20], X_test[21], X_test[22], X_test[23],\n",
    "                                 X_test[24], X_test[25], X_test[26], X_test[27],\n",
    "                                 X_test[28], X_test[29], X_test[30], X_test[31]]))\n",
    "print(names_test[20:32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Young"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score: 73.42834124389613%\n",
      "0.7513691128148959\n"
     ]
    }
   ],
   "source": [
    "Y_young = np.array(df['young'])\n",
    "X_train_y, X_test_y, Y_train_y, Y_test_y = train_test_split(X99, Y_young, test_size=0.2)\n",
    "\n",
    "# Cross validation score\n",
    "c2 = np.mean(cross_val_score(MLPClassifier(), X99, Y_young, cv=6))\n",
    "print('Cross Validation score: ' + str(100*c2) + '%')\n",
    "\n",
    "# 'By hand'\n",
    "clf_neuralNetwork_young = MLPClassifier()\n",
    "clf_neuralNetwork_young.fit(X_train_y, Y_train_y)\n",
    "print(clf_neuralNetwork_young.score(X_test_y, Y_test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 0 1 0 1 1]\n",
      "[4020 4021 4022 4023 4024 4025 4026 4027 4028 4029 4030 4031]\n"
     ]
    }
   ],
   "source": [
    "# Manual testing (possible because dataset already shuffled)\n",
    "ratio_train = 0.8\n",
    "names = np.array(df['file_name'])\n",
    "X_train, X_test = X99[:int(ratio_train*len(X99))], X99[int(ratio_train*len(X99)):] \n",
    "Y_train, Y_test = Y_young[:int(ratio_train*len(Y_young))], Y_young[int(ratio_train*len(Y_young)):]\n",
    "clf_neuralNetwork_mt = MLPClassifier()\n",
    "clf_neuralNetwork_mt.fit(X_train, Y_train)\n",
    "names_train, names_test = names[:int(ratio_train*len(X99))], names[int(ratio_train*len(X99)):]\n",
    "print(clf_neuralNetwork_mt.predict([X_test[20], X_test[21], X_test[22], X_test[23],\n",
    "                                 X_test[24], X_test[25], X_test[26], X_test[27],\n",
    "                                 X_test[28], X_test[29], X_test[30], X_test[31]]))\n",
    "print(names_test[20:32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score: 87.62370363069026%\n",
      "Splited data score: 0.8751369112814896\n"
     ]
    }
   ],
   "source": [
    "Y_smile = np.array(df['smiling'])\n",
    "X_train_s, X_test_s, Y_train_s, Y_test_s = train_test_split(X99, Y_smile, test_size=0.2)\n",
    "\n",
    "# Cross validation score\n",
    "c3 = np.mean(cross_val_score(MLPClassifier(), X99, Y_smile, cv=6))\n",
    "print('Cross Validation score: ' + str(100*c3) + '%')\n",
    "\n",
    "# 'By hand'\n",
    "clf_neuralNetwork_smile = MLPClassifier()\n",
    "clf_neuralNetwork_smile.fit(X_train_s, Y_train_s)\n",
    "print('Splited data score:', clf_neuralNetwork_smile.score(X_test_s, Y_test_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 0 1 1 0 1 1]\n",
      "[4020 4021 4022 4023 4024 4025 4026 4027 4028 4029 4030 4031]\n"
     ]
    }
   ],
   "source": [
    "# Manual testing (possible because dataset already shuffled)\n",
    "ratio_train = 0.8\n",
    "names = np.array(df['file_name'])\n",
    "X_train, X_test = X99[:int(ratio_train*len(X99))], X99[int(ratio_train*len(X99)):] \n",
    "Y_train, Y_test = Y_smile[:int(ratio_train*len(Y_smile))], Y_smile[int(ratio_train*len(Y_smile)):]\n",
    "clf_neuralNetwork_mt = MLPClassifier()\n",
    "clf_neuralNetwork_mt.fit(X_train, Y_train)\n",
    "names_train, names_test = names[:int(ratio_train*len(X99))], names[int(ratio_train*len(X99)):]\n",
    "print(clf_neuralNetwork_mt.predict([X_test[20], X_test[21], X_test[22], X_test[23],\n",
    "                                 X_test[24], X_test[25], X_test[26], X_test[27],\n",
    "                                 X_test[28], X_test[29], X_test[30], X_test[31]]))\n",
    "print(names_test[20:32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eyeglasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score: 84.14074147390059%\n",
      "Splited data score: 0.8324205914567361\n"
     ]
    }
   ],
   "source": [
    "Y_eyeglass = np.array(df['eyeglasses'])\n",
    "X_train_e, X_test_e, Y_train_e, Y_test_e = train_test_split(X99, Y_eyeglass, test_size=0.2)\n",
    "\n",
    "# Cross validation score\n",
    "c4 = np.mean(cross_val_score(MLPClassifier(), X99, Y_eyeglass, cv=6))\n",
    "print('Cross Validation score: ' + str(100*c4) + '%')\n",
    "\n",
    "# 'By hand'\n",
    "clf_neuralNetwork_eyeglass = MLPClassifier()\n",
    "clf_neuralNetwork_eyeglass.fit(X_train_e, Y_train_e)\n",
    "print('Splited data score:', clf_neuralNetwork_eyeglass.score(X_test_e, Y_test_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 1 0 0 0 0]\n",
      "[4020 4021 4022 4023 4024 4025 4026 4027 4028 4029 4030 4031]\n"
     ]
    }
   ],
   "source": [
    "# Manual testing (possible because dataset already shuffled)\n",
    "ratio_train = 0.8\n",
    "names = np.array(df['file_name'])\n",
    "X_train, X_test = X99[:int(ratio_train*len(X99))], X99[int(ratio_train*len(X99)):] \n",
    "Y_train, Y_test = Y_eyeglass[:int(ratio_train*len(Y_eyeglass))], Y_eyeglass[int(ratio_train*len(Y_eyeglass)):]\n",
    "clf_neuralNetwork_mt = MLPClassifier()\n",
    "clf_neuralNetwork_mt.fit(X_train, Y_train)\n",
    "names_train, names_test = names[:int(ratio_train*len(X99))], names[int(ratio_train*len(X99)):]\n",
    "print(clf_neuralNetwork_mt.predict([X_test[20], X_test[21], X_test[22], X_test[23],\n",
    "                                 X_test[24], X_test[25], X_test[26], X_test[27],\n",
    "                                 X_test[28], X_test[29], X_test[30], X_test[31]]))\n",
    "print(names_test[20:32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score: 52.88110634668142%\n"
     ]
    }
   ],
   "source": [
    "Y_multi = np.array(df[['eyeglasses', 'smiling', 'young','human']])\n",
    "X_train_multi, X_test_multi, Y_train_multi, Y_test_multi = train_test_split(X99, Y_multi, test_size=0.2)\n",
    "\n",
    "# Cross validation score\n",
    "c5 = np.mean(cross_val_score(MLPClassifier(), X99, Y_multi, cv=6))\n",
    "print('Cross Validation score: ' + str(100*c5) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hair Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3902, 256, 256)\n",
      "(3902, 65536)\n",
      "Time to compute pca.fit_transform: 1.79 min\n"
     ]
    }
   ],
   "source": [
    "df2 = df[df['hair_color'] != -1] \n",
    "df2.shape\n",
    "pics_hair = import_pictures(df2, _as_black_white=True)\n",
    "print(pics_hair.shape)\n",
    "imgs_hair = np.array([preprocessing.scale(pics_hair[k]) for k in range(len(pics_hair))])\n",
    "pics_lin_hair = to_vector(data=imgs_hair)\n",
    "print(pics_lin_hair.shape)\n",
    "\n",
    "# PCA\n",
    "s = time.time()\n",
    "pca = PCA()\n",
    "X_hair = pca.fit_transform(pics_lin_hair)\n",
    "t = time.time()\n",
    "print('Time to compute pca.fit_transform: ' + str(int(100*(t - s)/60)/100) + ' min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score: 44.99976570361283%\n",
      "Splited data score: 0.4660691421254802\n"
     ]
    }
   ],
   "source": [
    "Y_hair = np.array(df2['hair_color'])\n",
    "X_train_hair, X_test_hair, Y_train_hair, Y_test_hair = train_test_split(X_hair, Y_hair, test_size=0.2)\n",
    "\n",
    "# Cross validation score\n",
    "c5 = np.mean(cross_val_score(MLPClassifier(), X_hair, Y_hair, cv=6))\n",
    "print('Cross Validation score: ' + str(100*c5) + '%')\n",
    "\n",
    "# 'By hand'\n",
    "clf_neuralNetwork_hair = MLPClassifier()\n",
    "clf_neuralNetwork_hair.fit(X_train_hair, Y_train_hair)\n",
    "print('Splited data score:', clf_neuralNetwork_hair.score(X_test_hair, Y_test_hair))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras - CNN for hair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6fd9f5f85c31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loading data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hair_color'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpics_hair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_pictures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_as_black_white\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpics_hair_bw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_pictures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_as_black_white\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "df2 = df[df['hair_color'] != -1] \n",
    "df2.shape\n",
    "pics_hair = import_pictures(df2, _as_black_white=False)\n",
    "pics_hair_bw = import_pictures(df2, _as_black_white=True)\n",
    "Y_hair = np.array(df2['hair_color'])\n",
    "print(pics_hair.shape)\n",
    "\n",
    "# Splitting data \n",
    "X_train_hair, X_test_hair, Y_train_hair, Y_test_hair = train_test_split(pics_hair, Y_hair, test_size=0.2)\n",
    "Y_train_hair = to_categorical(Y_train_hair)\n",
    "Y_test_hair = to_categorical(Y_test_hair)\n",
    "\n",
    "# Splitting for black and white\n",
    "X_train_hair_bw, X_test_hair_bw, Y_train_hair_bw, Y_test_hair_bw = train_test_split(pics_hair_bw, \n",
    "                                                                                    Y_hair, test_size=0.2)\n",
    "a,b,c = X_train_hair_bw.shape\n",
    "d,e,f = X_test_hair_bw.shape\n",
    "X_train_hair_bw = X_train_hair_bw.reshape(a,b,c,1)\n",
    "X_test_hair_bw = X_test_hair_bw.reshape(d,e,f,1)\n",
    "Y_train_hair_bw = to_categorical(Y_train_hair_bw)\n",
    "Y_test_hair_bw = to_categorical(Y_test_hair_bw)\n",
    "print(pics_hair_bw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3121 samples, validate on 781 samples\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "#create model\n",
    "model = Sequential()\n",
    "\n",
    "#add model layers\n",
    "'''model.add(ZeroPadding2D((1,1),input_shape=(256,256,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))'''\n",
    "#model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(256,256,3)))\n",
    "#model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "\n",
    "\n",
    "\"\"\"model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\"\"\"\n",
    "\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#model.add(ZeroPadding2D((1,1)))\n",
    "#model.add(Conv2D(16, kernel_size=3, activation='relu'))\n",
    "#model.add(Conv2D(16, kernel_size=3, activation='relu'))\n",
    "\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\"\"\"model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(256,256,3)))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(256,256,3)))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\"\"\"\n",
    "\n",
    "model.add(Flatten(input_shape=(256,256,1)))\n",
    "\n",
    "model.add(Dense(128, activation='softmax'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "#Compiling\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#train the model\n",
    "model.fit(X_train_hair_bw, Y_train_hair_bw, validation_data=(X_test_hair_bw, Y_test_hair_bw), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cfe0a22483f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_hair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test_hair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test_hair, Y_test_hair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(pics_hair_bw[200:210])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-50cc35e90a1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hair_color'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df2 = df[df['hair_color'] != -1] \n",
    "df2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pics_hair = import_pictures(df2, _as_black_white=False)\n",
    "[width, height] = pics_hair.size "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
